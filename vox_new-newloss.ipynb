{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n",
    "from baseline._dependencies_densenet import *\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveRegressor, LinearRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if os.path.exists(\"D:\\\\down\"):\n",
    "#    data_directory = \"D:\\\\down\"\n",
    "#    pytorch3path = \"D:\\\\下载\\\\EfficientNet-PyTorch-3D-master\"\n",
    "    \n",
    "#else:\n",
    "#    data_directory = \"D:\\\\down\"\n",
    "#    pytorch3path = \"D:\\\\下载\\\\EfficientNet-PyTorch-3D-master\"\n",
    "    \n",
    "#mri_types = (\"Flair_res111\", \"T1_res111\", \"T13D_res111\", \"T2_res111\")\n",
    "#SIZE = 128\n",
    "#NUM_IMAGES = 64\n",
    "\n",
    "#sys.path.append(pytorch3path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform .nrrd to .nii \n",
    "# Load images\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def _load_raw_image(in_files, out_files):\n",
    "    img = sitk.ReadImage(in_files)\n",
    "    sitk.WriteImage(img, out_files)\n",
    "    img = sitk.ReadImage(out_files)\n",
    "    return img\n",
    "\n",
    "_load_raw_image(\"D:\\\\down\\\\Pcnls_3\\\\Pcnls_baseline\\\\T1.nrrd\",\n",
    "               \"D:\\\\down\\\\Pcnls_3\\\\Pcnls_baseline\\\\T1.nii.gz\")\n",
    "set_of_files1=(os.path.join(\"D:\\\\down\\\\\",\"Pcnls_3\\\\Pcnls_baseline\\\\\",item) for item in (\"T1.nrrd\", \"T2.nrrd\", \"T13D.nrrd\"))\n",
    "set_of_files2=(os.path.join(\"D:\\\\down\\\\\",\"Pcnls_3\\\\Pcnls_baseline\\\\\",item) for item in (\"T1.nii.gz\",\"T2.nii.gz\", \"T13D.nii.gz\"))\n",
    "for i, j in zip(set_of_files1, set_of_files2):\n",
    "    print(i, j)\n",
    "    _load_raw_image(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform .nrrd to .nii \n",
    "# Load images\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def load_raw_image(scan_id, in_files, out_files):\n",
    "    for image_file1, image_file2 in zip(in_files, out_files):\n",
    "        in_file = f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\{image_file1}\"\n",
    "        img = sitk.ReadImage(in_file)\n",
    "        out_file = f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\{image_file2}\"\n",
    "        sitk.WriteImage(img, out_file)\n",
    "        #img = sitk.ReadImage(out_file)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, CacheDataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    Transform,\n",
    "    MapTransform,\n",
    "    Randomizable,\n",
    "    AddChannel,\n",
    "    AddChanneld,\n",
    "    AsChannelFirstd,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    SaveImage,\n",
    "    LoadImaged,\n",
    "    SaveImaged,\n",
    "    Lambda,\n",
    "    Lambdad,\n",
    "    RandSpatialCrop,\n",
    "    RandSpatialCropd,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ToTensor,\n",
    "    ToTensord,\n",
    "    Orientation, \n",
    "    Rotate,\n",
    "    Rotated,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    Spacing,\n",
    "    Spacingd\n",
    "    \n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "from monai.metrics import compute_meandice\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sigmoid\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "        \"image\": \"D:\\\\down\\\\Pcnls_3\\\\Pcnls_baseline\\\\T13D_res111.nii.gz\",\n",
    "       # \"label\": \"/content/maskT1.nrrd\"\n",
    "    }\n",
    "T1 = LoadImaged(keys=[\"image\"])(inputs)\n",
    "\n",
    "print(f\"image.shape: {T1['image'].shape}\")\n",
    "print(f\"image.shape: {T1['image'].min()}\")\n",
    "print(f\"image.shape: {T1['image'].max()}\")\n",
    "print(f\"image.shape: {T1['image'].mean()}\")\n",
    "\n",
    "T2 = ScaleIntensityd(keys=[\"image\"])(T1)\n",
    "\n",
    "print(f\"image.shape: {T2['image'].shape}\")\n",
    "print(f\"image.shape: {T2['image'].min()}\")\n",
    "print(f\"image.shape: {T2['image'].max()}\")\n",
    "print(f\"image.shape: {T2['image'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plt(array, title):\n",
    "    rows, cols = 1, 3\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "    plt.figure(1)\n",
    "    plt.title(title, {\"fontsize\": 12,\n",
    "                      \"color\": \"black\"})\n",
    "\n",
    "    ax1 = plt.subplot(rows, cols, 1)\n",
    "    ax2 = plt.subplot(rows, cols, 2)\n",
    "    ax3 = plt.subplot(rows, cols, 3)\n",
    "\n",
    "    x = array.shape[0] // 2\n",
    "    y = array.shape[1] // 2\n",
    "    z = array.shape[2] // 2\n",
    "\n",
    "    plt.sca(ax1)\n",
    "    plt.imshow(array[x, :, :], cmap=\"gray\")\n",
    "    plt.sca(ax2)\n",
    "    plt.imshow(array[:, y, :], cmap=\"gray\")\n",
    "    plt.sca(ax3)\n",
    "    plt.imshow(array[:, :, z], cmap=\"gray\")\n",
    "    \n",
    "    plt.savefig(\".\\\\test.jpg\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plt(T1[\"image\"], \"before resampling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c51ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = AddChanneld(keys=[\"image\"])(copy.deepcopy(T1))\n",
    "T2 = Spacingd(keys=[\"image\"], pixdim=(1,1,1))(T2)\n",
    "T2 = Resized(keys=[\"image\"], spatial_size=(256,256,128))(T2)\n",
    "#T2 = ScaleIntensityd(keys=[\"image\"])(T2)\n",
    "print(f\"image.shape: {T2['image'].shape}\")\n",
    "print(f\"image.shape: {T2['image'].min()}\")\n",
    "print(f\"image.shape: {T2['image'].max()}\")\n",
    "print(f\"image.shape: {T2['image'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa994f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plt(T2[\"image\"][0], \"after resampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image.image import _crop_img_to as crop_img_to\n",
    "from nilearn.image.image import check_niimg\n",
    "from nilearn.image import new_img_like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foreground_from_set_of_files(scan_id, set_of_files, background_value=0, tolerance=0.00001):\n",
    "    #set_of_files=[\"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\Flair_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T1_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T13D_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T2_res111.nii.gz\"]\n",
    "    load_raw_image(scan_id, \n",
    "                   in_files=(\"T1_res111.nrrd\", \"T2_res111.nrrd\", \"T13D_res111.nrrd\"), \n",
    "                   out_files=set_of_files)\n",
    "    foreground = np.zeros((256, 256, 128), dtype=np.int8)\n",
    "    for i, image_file in enumerate(set_of_files):\n",
    "        dict = {\"image\": f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\{image_file}\"}\n",
    "        #print(dict)\n",
    "        image = LoadImaged(keys=[\"image\"])(dict)\n",
    "        #print(image)\n",
    "        image = AddChanneld(keys=[\"image\"])(copy.deepcopy(image))\n",
    "        image = Spacingd(keys=[\"image\"], pixdim=(1,1,1))(image)\n",
    "        image = Resized(keys=[\"image\"], spatial_size=(256,256,128))(image)\n",
    "        image = ScaleIntensityd(keys=[\"image\"])(image)\n",
    "        output_dir = f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\\"\n",
    "        #output_dir = os.path.join(\"D:\\\\down\\\\\",\"Pcnls_1\\\\Pcnls_baseline\\\\\")\n",
    "        SaveImaged(keys=[\"image\"], output_dir=output_dir)(image)\n",
    "        image = image[\"image\"][0]\n",
    "        is_foreground = np.logical_or(image<(background_value-tolerance),\n",
    "                                      image>(background_value+tolerance))\n",
    "        #if i == 0:\n",
    "            #foreground = np.zeros(is_foreground.shape, dtype=np.int8)\n",
    "        foreground[is_foreground] = 1\n",
    "    \n",
    "    return foreground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_files = (\"T1_res111.nii.gz\", \"T2_res111.nii.gz\", \"T13D_res111.nii.gz\")\n",
    "data_directory=\"D:\\\\down\"\n",
    "train_df = pd.read_csv(f\"{data_directory}\\\\os.csv\")\n",
    "scan_ids = list(train_df[\"Patient\"])\n",
    "for scan_id in scan_ids:\n",
    "    get_foreground_from_set_of_files(scan_id, set_of_files, background_value=0, tolerance=0.00001)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foreground_from_set_of_files_withoutsave(scan_id, set_of_files, background_value=0, tolerance=0.00001):\n",
    "    #set_of_files=[\"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\Flair_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T1_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T13D_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T2_res111.nii.gz\"]\n",
    "    load_raw_image(scan_id, \n",
    "                   in_files=(\"T1_res111.nrrd\", \"T2_res111.nrrd\", \"T13D_res111.nrrd\"), \n",
    "                   out_files=set_of_files)\n",
    "    foreground = np.zeros((256, 256, 128), dtype=np.int8)\n",
    "    for i, image_file in enumerate(set_of_files):\n",
    "        dict = {\"image\": f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\{image_file}\"}\n",
    "        #print(dict)\n",
    "        image = LoadImaged(keys=[\"image\"])(dict)\n",
    "        image = AddChanneld(keys=[\"image\"])(copy.deepcopy(image))\n",
    "        image = Spacingd(keys=[\"image\"], pixdim=(1,1,1))(image)\n",
    "        image = Resized(keys=[\"image\"], spatial_size=(256,256,128))(image)\n",
    "        image = ScaleIntensityd(keys=[\"image\"])(image)\n",
    "        image = image[\"image\"][0]\n",
    "        is_foreground = np.logical_or(image<(background_value-tolerance),\n",
    "                                      image>(background_value+tolerance))\n",
    "        #if i == 0:\n",
    "            #foreground = np.zeros(is_foreground.shape, dtype=np.int8)\n",
    "        foreground[is_foreground] = 1\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66716e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_files = (\"T1_res111.nii.gz\", \"T2_res111.nii.gz\", \"T13D_res111.nii.gz\")\n",
    "nii_foreground = get_foreground_from_set_of_files_withoutsave(\"Pcnls_1\", set_of_files)\n",
    "show_plt(nii_foreground, 'nii_foreground')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86540978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_index(foreground, rtol=1e-8):\n",
    "    \n",
    "    infinity_norm = max(-foreground.min(), foreground.max())\n",
    "    passes_threshold = np.logical_or(foreground<-rtol*infinity_norm,\n",
    "                                     foreground>rtol*infinity_norm) \n",
    "    #print(passes_threshold)\n",
    "    coords = np.array(np.where(passes_threshold))\n",
    "    #print(coords)\n",
    "   \n",
    "    start = coords.min(axis=1)\n",
    "    end = coords.max(axis=1) + 1\n",
    "    \n",
    "    start = np.maximum(start-1, 0)\n",
    "    end = np.minimum(end+1, foreground.shape[:3])\n",
    "    #print(start, end)\n",
    "      \n",
    "    slices = [slice(s, e) for s, e in zip(start, end)]\n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f99df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = get_multi_index(nii_foreground)\n",
    "print(crop)\n",
    "#crop_img_to(\"C:\\\\Users\\\\shezi\\\\T2_res111\\\\T2_res111_trans.nii.gz\", crop, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_images_list(scan_id, set_of_files, norm_set_of_files):\n",
    "#def get_crop_images(set_of_files, norm_set_of_files):\n",
    "    #set_of_files=[\"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\Flair_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T1_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T13D_res111.nii.gz\",\n",
    "    #              \"D:\\\\down\\\\Pcnls_1\\\\Pcnls_baseline\\\\T2_res111.nii.gz\"]\n",
    "    foreground = get_foreground_from_set_of_files_withoutsave(scan_id, set_of_files)\n",
    "    crop = get_multi_index(foreground)\n",
    "  \n",
    "    crop_images = []\n",
    "    for i, image_file in enumerate(norm_set_of_files):\n",
    "        file = f\"D:\\\\down\\\\{scan_id}\\\\Pcnls_baseline\\\\{image_file}\"\n",
    "        crop_image = crop_img_to(file, crop, copy=True).get_fdata()\n",
    "        #print(crop_image)\n",
    "        resize_crop_image = skTrans.resize(crop_image, (128,128,128), order=1, preserve_range=True)\n",
    "        norm_resize_crop_image = rescale_intensity(resize_crop_image)\n",
    "        crop_images.append(norm_resize_crop_image)\n",
    "    return crop_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_files = (\"T1_res111.nii.gz\",\"T2_res111.nii.gz\", \"T13D_res111.nii.gz\")\n",
    "norm_set_of_files = (  \n",
    "                     \"T1_res111\\\\T1_res111_trans.nii.gz\", \"T2_res111\\\\T2_res111_trans.nii.gz\", \"T13D_res111\\\\T13D_res111_trans.nii.gz\", \n",
    "                     )\n",
    "nii_crop_images_list = get_crop_images_list(\"Pcnls_3\", set_of_files, norm_set_of_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa75e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_norm_resize_crop_image = nii_crop_images_list[0]\n",
    "print(get_norm_resize_crop_image.dtype)\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.shape}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.min()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.max()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.mean()}\")\n",
    "show_plt(get_norm_resize_crop_image, \"norm_resize_crop_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_norm_resize_crop_image = nii_crop_images_list[1]\n",
    "print(get_norm_resize_crop_image.dtype)\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.shape}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.min()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.max()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.mean()}\")\n",
    "show_plt(get_norm_resize_crop_image, \"norm_resize_crop_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_norm_resize_crop_image = nii_crop_images_list[2]\n",
    "print(get_norm_resize_crop_image.dtype)\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.shape}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.min()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.max()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.mean()}\")\n",
    "show_plt(get_norm_resize_crop_image, \"norm_resize_crop_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2faf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [     \n",
    "        #AsChannelFirst(),\n",
    "        AddChannel(),\n",
    "        Rand3DElastic(#mode=(\"bilinear\", \"nearest\"),\n",
    "                      prob=0.25,\n",
    "                      sigma_range=(5, 7),\n",
    "                      magnitude_range=(50, 150),\n",
    "                      spatial_size=(128, 128, 128),\n",
    "                      #translate_range=(2, 2, 2),\n",
    "                      #rotate_range=(np.pi/36, np.pi/36, np.pi),\n",
    "                      #scale_range=(0.15, 0.15, 0.15),\n",
    "                      padding_mode=\"zeros\"),\n",
    "        \n",
    "         RandAffine(#mode=(\"bilinear\", \"nearest\"),\n",
    "                   prob=0.25,\n",
    "                   spatial_size=(128, 128, 128),\n",
    "                   translate_range=(0.5, 0.5, 0.5),\n",
    "                   rotate_range=(np.pi/36, np.pi/36, np.pi/4),\n",
    "                   scale_range=(0.15, 0.15, 0.15),\n",
    "                   padding_mode=\"zeros\"),\n",
    "        #Orientation(axcodes=\"PLI\"),\n",
    "        #RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        RandSpatialCrop(roi_size=(96, 96, 96)),\n",
    "       \n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        Resize(spatial_size=(128, 128, 128)),\n",
    "        #RandFlip(spatial_axis=0, prob=0.5),\n",
    "        ScaleIntensity(),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_norm_resize_crop_image = train_transforms(nii_crop_images_list[2])\n",
    "#print(get_norm_resize_crop_image.dtype)\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.shape}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.min()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.max()}\")\n",
    "print(f\"image.shape: {get_norm_resize_crop_image.mean()}\")\n",
    "show_plt(get_norm_resize_crop_image[0], \"norm_resize_crop_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_3d(scan_id=\"Pcnls_1\", data_directory=\"D:\\\\down\", split=\"Pcnls_baseline\"):\n",
    "    set_of_files = (\"T1_res111.nii.gz\",\"T2_res111.nii.gz\", \"T13D_res111.nii.gz\")\n",
    "    norm_set_of_files = (\"T1_res111\\\\T1_res111_trans.nii.gz\",  \"T2_res111\\\\T2_res111_trans.nii.gz\", \"T13D_res111\\\\T13D_res111_trans.nii.gz\", \n",
    "                        )\n",
    "    images_list = get_crop_images_list(scan_id, set_of_files, norm_set_of_files)\n",
    "    return images_list\n",
    "    #middle = len(files) // 2 \n",
    "    #num_imgs2 = num_imgs // 2\n",
    "    #p1 = max(0, middle - num_imgs2)\n",
    "    #p2 = min(len(files), middle + num_imgs2)\n",
    "    #img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T\n",
    "    \n",
    "    #if img3d.shape[-1] < num_imgs:\n",
    "    #    n_zero = np.zeros((img_size, img_size, num_imgs-img3d.shape[-1]))\n",
    "    #    img3d = np.concatenate((img3d, n_zero), axis=-1)\n",
    "     \n",
    "    #if np.min(img3d) < np.max(img3d):\n",
    "    #    img3d = img3d - np.min(img3d)\n",
    "    #    img3d = img3d / np.max(img3d)\n",
    "    \n",
    "    #return np.expand_dims(img3d, 0)\n",
    "   \n",
    "\n",
    "a = load_image_3d(scan_id=\"Pcnls_1\")\n",
    "print(a[0].shape)\n",
    "#print(np.min(a), np.max(a), np.mean(a), np.median(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory=\"D:\\\\down\"\n",
    "train_df = pd.read_csv(f\"{data_directory}\\\\os.csv\")\n",
    "display(train_df)\n",
    "\n",
    "df_train, df_valid = sk_model_selection.train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.4,\n",
    "    random_state=12,\n",
    "    stratify=train_df[\"OS 1 year\"],\n",
    ")\n",
    "\n",
    "dummies_train = pd.get_dummies(df_train[\"OS 1 year\"]) # Classification\n",
    "products_train = dummies_train.columns\n",
    "y_train = dummies_train.values\n",
    "print(y_train)\n",
    "dummies_valid = pd.get_dummies(df_valid[\"OS 1 year\"]) # Classification\n",
    "products_valid = dummies_valid.columns\n",
    "y_valid = dummies_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()#tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0533cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.dataset):\n",
    "    def __init__(self, paths, targets, transforms=None):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.transforms = transforms\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        scan_id = self.paths[index]\n",
    "        if self.targets is None:\n",
    "            data = load_image_3d(scan_id, data_directory=\"D:\\\\down\", split=self.split)\n",
    "            data = np.array(data)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(data)\n",
    "            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n",
    "        else:\n",
    "            data = load_image_3d(scan_id, data_directory=\"D:\\\\down\", split=\"Pcnls_baseline\")\n",
    "            data = np.array(data)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(data)\n",
    "            y = torch.tensor(self.targets[index], dtype=torch.float32)\n",
    "            return {\"X\": torch.tensor(data).float(), \"y\": y}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Model(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super().__init__()\n",
    "#        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=4)\n",
    "#        n_features = self.net._fc.in_features\n",
    "#        self.net._fc = nn.Linear(in_features=n_features, out_features=2, bias=True)\n",
    "    \n",
    "#    def forward(self, x):\n",
    "#        out = self.net(x)\n",
    "#        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 3\n",
    "\n",
    "def show_plt_(img):\n",
    "    plt.figure(figsize=(15,15), dpi=80)\n",
    "    plt.figure(1)\n",
    "\n",
    "    ax1 = plt.subplot(rows, cols, 1)\n",
    "    ax2 = plt.subplot(rows, cols, 2)\n",
    "    ax3 = plt.subplot(rows, cols, 3)\n",
    " \n",
    "    x = img.shape[0] // 2\n",
    "    y = img.shape[1] // 2\n",
    "    z = img.shape[2] // 2\n",
    "\n",
    "    plt.sca(ax1)\n",
    "    plt.imshow(img[x, :, :], cmap=\"Spectral\")\n",
    "     \n",
    "    plt.sca(ax2)\n",
    "    plt.imshow(img[:, y, :], cmap=\"Spectral\")\n",
    "    \n",
    "    plt.sca(ax3)\n",
    "    plt.imshow(img[:, :, z], cmap=\"Spectral\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_name(model):\n",
    "    layer_name = None\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, nn.Conv3d): \n",
    "            layer_name = name\n",
    "        #print(m)\n",
    "        #print(layer_name)\n",
    "    return layer_name\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#monai.networks.nets.resnet.resnet10(n_input_channels=2, n_classes=2).to(device)\n",
    "#get_last_conv_name(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefaa57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet10 = monai.networks.nets.resnet.resnet10(spatial_dims=3, n_input_channels=2).to(device)\n",
    "model_file = \"D:\\\\down\\\\MedicalNet_pytorch_files2\\\\resnet_10.pth\"\n",
    "checkpoint = torch.load(model_file)\n",
    "#model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "print(get_last_conv_name(model_resnet10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=2, out_channels=2)#.to(device)\n",
    "#model = Model()\n",
    "#model.to(device)\n",
    "#checkpoint = torch.load(modelfile)\n",
    "#model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "#print(get_last_conv_name(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__all__ = [\"relationship_learning\", \"direct_relationship_learning\"]\n",
    "#from sklearn.calibration import CalibratedClassifierCV\n",
    "def calibrate(logits, labels):\n",
    "    \"\"\"\n",
    "    calibrate by minimizing negative log likelihood.\n",
    "    :param logits: pytorch tensor with shape of [N, N_c]\n",
    "    :param labels: pytorch tensor of labels\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    scale = nn.Parameter(torch.ones(\n",
    "        1, 1, dtype=torch.float32), requires_grad=True)\n",
    "    optim = torch.optim.LBFGS([scale])\n",
    "\n",
    "    def loss():\n",
    "        optim.zero_grad()\n",
    "        lo = torch.nn.CrossEntropyLoss()(torch.tensor(logits * scale, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32))\n",
    "        lo.backward()\n",
    "        return lo\n",
    "\n",
    "    state = optim.state[scale]\n",
    "    for i in range(20):\n",
    "        optim.step(loss)\n",
    "        print(f'calibrating, {scale.item()}')\n",
    "        if state['n_iter'] < optim.state_dict()['param_groups'][0]['max_iter']:\n",
    "            break\n",
    "\n",
    "    return scale.item()\n",
    "\n",
    "\n",
    "def softmax_np(x):\n",
    "    max_el = np.max(x, axis=1, keepdims=True)\n",
    "    #print(\"max_el's dim{}\".format(max_el.shape))\n",
    "    x = x - max_el\n",
    "    x = np.exp(x)\n",
    "    s = np.sum(x, axis=1, keepdims=True)\n",
    "    return x / s\n",
    "\n",
    "\n",
    "def relationship_learning(train_logits, train_labels, validation_logits, validation_labels):\n",
    "    \"\"\"\n",
    "    :param train_logits (ImageNet logits): [N, N_p], where N_p is the number of classes in pre-trained dataset\n",
    "    :param train_labels:  [N], where 0 <= each number < N_t, and N_t is the number of target dataset\n",
    "    :param validation_logits (ImageNet logits): [N, N_p]\n",
    "    :param validation_labels:  [N]\n",
    "    :return: [N_c, N_p] matrix  representing the conditional probability p(pre-trained class | target_class)\n",
    "     \"\"\"\n",
    "\n",
    "    # convert logits to probabilities\n",
    "    train_probabilities = softmax_np(train_logits * 0.8840456604957581)\n",
    "    validation_probabilities = softmax_np(validation_logits * 0.8840456604957581)\n",
    "  \n",
    "\n",
    "    all_probabilities = np.concatenate((train_probabilities, validation_probabilities))\n",
    "    all_labels = np.concatenate((train_labels, validation_labels))\n",
    "\n",
    "    Cs = []\n",
    "    accs = []\n",
    "    classifiers = []\n",
    "    for C in [1e4, 3e3, 1e3, 3e2, 1e2, 3e1, 1e1, 3.0, 1.0, 3e-1, 1e-1, 3e-2, 1e-2, 3e-3, 1e-3, 3e-4, 1e-4]:\n",
    "        cls = LogisticRegression(multi_class=\"multinomial\", C=C, fit_intercept=False)\n",
    "        train_probabilities, train_labels = shuffle(train_probabilities, train_labels)\n",
    "        ind_train = np.argmax(train_labels, axis=1) \n",
    "        cls.fit(train_probabilities, ind_train)\n",
    "        val_predict = cls.predict(validation_probabilities)\n",
    "        ind_valid = np.argmax(validation_labels, axis=1) \n",
    "        val_acc = np.sum((val_predict == ind_valid).astype(np.float)) / len(validation_labels)\n",
    "        Cs.append(C)\n",
    "        accs.append(val_acc)\n",
    "        classifiers.append(cls)\n",
    "    #cls = LinearRegression()\n",
    "    #train_probabilities, train_labels = shuffle(train_probabilities, train_labels)\n",
    "    #cls.fit(train_probabilities, train_labels)\n",
    "    #val_predict = cls.predict(validation_probabilities)\n",
    "    #val_acc = np.sum((val_predict == validation_labels).astype(np.float)) / len(validation_labels)\n",
    "    #Cs.append(C)\n",
    "    #accs.append(val_acc)\n",
    "    #classifiers.append(cls)\n",
    "    \n",
    "    accs = np.asarray(accs)\n",
    "    ind = int(np.argmax(accs))\n",
    "    cls = classifiers[ind]\n",
    "    del classifiers\n",
    "    print(cls)\n",
    "    print(cls.coef_.T)\n",
    "    \n",
    "    validation_logits = np.matmul(validation_probabilities, cls.coef_.T)\n",
    "    validation_logits = torch.from_numpy(validation_logits.astype(np.float32))\n",
    "    validation_labels = torch.from_numpy(validation_labels)\n",
    "    #scale = calibrate(validation_logits, validation_labels)\n",
    "    #print(scale.shape)\n",
    "    p_target_given_pretrain = softmax_np(\n",
    "        cls.coef_.T)# * scale)  # shape of [N_p, N_c], conditional probability p(target_class | pre-trained class)\n",
    "   \n",
    "    # in the paper, both ys marginal and yt marginal are computed\n",
    "    # here we only use ys marginal to make sure p_pretrain_given_target is a valid conditional probability\n",
    "    # (make sure p_pretrain_given_target[i] sums up to 1)\n",
    "    pretrain_marginal = np.mean(all_probabilities, axis=0).reshape(\n",
    "        (-1, 1))  # shape of [N_p, 1]\n",
    "    \n",
    "    p_joint_distribution = (p_target_given_pretrain * pretrain_marginal).T\n",
    "    p_pretrain_given_target = p_joint_distribution / \\\n",
    "        np.sum(p_joint_distribution, axis=1, keepdims=True)\n",
    "    return p_pretrain_given_target \n",
    "\n",
    "\n",
    "def direct_relationship_learning(train_logits, train_labels, validation_logits, validation_labels):\n",
    "    \"\"\"\n",
    "    The direct approach of learning category relationship.\n",
    "    :param train_logits (ImageNet logits): [N, N_p], where N_p is the number of classes in pre-trained dataset\n",
    "    :param train_labels:  [N], where 0 <= each number < N_t, and N_t is the number of target dataset\n",
    "    :param validation_logits (ImageNet logits): [N, N_p]\n",
    "    :param validation_labels:  [N]\n",
    "    :return: [N_c, N_p] matrix representing the conditional probability p(pre-trained class | target_class)\n",
    "     \"\"\"\n",
    "    # convert logits to probabilities\n",
    "    train_probabilities = softmax_np(train_logits * 0.8840456604957581)\n",
    "    validation_probabilities = softmax_np(validation_logits * 0.8840456604957581)\n",
    "\n",
    "    all_probabilities = np.concatenate((train_probabilities, validation_probabilities))\n",
    "    all_labels = np.concatenate((train_labels, validation_labels))\n",
    "    \n",
    "    N_p = all_probabilities,shape[1]\n",
    "    N_t = np.max(all_labels) + 1 # the number of target classes\n",
    "    conditional = []\n",
    "    for i in range(N_t):\n",
    "        this_class = all_probabilities[all_labels == i]\n",
    "        average = np.mean(this_class, axis=0, keepdims=True)\n",
    "        conditional.append(average)\n",
    "    print(np.concatenate(conditional).shape)\n",
    "    return np.concatenate(conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d40b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    AsChannelFirst,\n",
    "    Orientation,\n",
    "    RandAffine,\n",
    "    Rand3DElastic,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    RandZoom,  \n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "               \n",
    "train_transforms = Compose(\n",
    "    [     \n",
    "        #AsChannelFirst(),\n",
    "       \n",
    "        Rand3DElastic(#mode=(\"bilinear\", \"nearest\"),\n",
    "                      prob=0.25,\n",
    "                      sigma_range=(5, 7),\n",
    "                      magnitude_range=(50, 150),\n",
    "                      spatial_size=(128, 128, 128),\n",
    "                      #translate_range=(2, 2, 2),\n",
    "                      #rotate_range=(np.pi/36, np.pi/36, np.pi),\n",
    "                      #scale_range=(0.15, 0.15, 0.15),\n",
    "                      padding_mode=\"zeros\"),\n",
    "        \n",
    "         RandAffine(#mode=(\"bilinear\", \"nearest\"),\n",
    "                   prob=0.25,\n",
    "                   spatial_size=(128, 128, 128),\n",
    "                   translate_range=(0.5, 0.5, 0.5),\n",
    "                   rotate_range=(np.pi/36, np.pi/36, np.pi/4),\n",
    "                   scale_range=(0.15, 0.15, 0.15),\n",
    "                   padding_mode=\"zeros\"),\n",
    "        #Orientation(axcodes=\"PLI\"),\n",
    "        #RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        #RandSpatialCrop(roi_size=(96, 96, 96)),\n",
    "        Resize(spatial_size=(128, 128, 128)),\n",
    "        #RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        #RandFlip(spatial_axis=0, prob=0.5),\n",
    "        ScaleIntensity(),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "valid_transforms = Compose(\n",
    "    [   \n",
    "        #AsChannelFirst(),\n",
    "        Resize(spatial_size=(128, 128, 128)),\n",
    "        #RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        #RandFlip(spatial_axis=0, prob=0.5),\n",
    "        ScaleIntensity(),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data_retriever = Dataset(\n",
    "    paths=df_train[\"Patient\"].values,\n",
    "    targets=y_train,\n",
    "    transforms=train_transforms\n",
    ")\n",
    "valid_data_retriever = Dataset(\n",
    "    paths=df_valid[\"Patient\"].values,\n",
    "    targets=y_valid,\n",
    "    transforms=valid_transforms\n",
    ")\n",
    "   \n",
    "train_loader = DataLoader(#torch_data.DataLoader(\n",
    "    train_data_retriever,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    "    #collate_fn=pad_list_data_collate\n",
    ")\n",
    "valid_loader = DataLoader(#torch_data.DataLoader(\n",
    "    valid_data_retriever,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    "    #collate_fn=pad_list_data_collate\n",
    ")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plt(train_data_retriever[0][\"X\"][0], \"train_0\")\n",
    "show_plt(train_data_retriever[0][\"X\"][1], \"train_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plt(valid_data_retriever[0][\"X\"][0], \"valid_0\")\n",
    "show_plt(valid_data_retriever[0][\"X\"][1], \"valid_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet10_F(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNet10_F, self).__init__()\n",
    "        model_resnet10.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "        self.conv1 = model_resnet10.conv1\n",
    "        self.bn1 = model_resnet10.bn1\n",
    "        self.relu = model_resnet10.relu\n",
    "        self.maxpool = model_resnet10.maxpool\n",
    "        self.layer1 = model_resnet10.layer1\n",
    "        self.layer2 = model_resnet10.layer2\n",
    "        self.layer3 = model_resnet10.layer3\n",
    "        self.layer4 = model_resnet10.layer4\n",
    "        self.avgpool = model_resnet10.avgpool\n",
    "        self.__in_features = model_resnet10.fc.in_features\n",
    "        self.__out_features = model_resnet10.fc.out_features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "        \n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        #print(self.__in_features)\n",
    "        return self.__in_features\n",
    "    \n",
    "    @property\n",
    "    def output_num(self):\n",
    "        #print(self.__out_features)\n",
    "        return self.__out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf61fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet10_C(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNet10_C, self).__init__()\n",
    "        model_resnet10.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "        self.fc = model_resnet10.fc\n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ec844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.f_net = ResNet10_F(pretrained=True)\n",
    "        self.c_net_1 = ResNet10_C(pretrained=True)\n",
    "        \n",
    "        self.c_net_2 = nn.Linear(self.f_net.output_dim, self.f_net.output_num)\n",
    "        self.c_net_2.weight.data.normal_(0, 0.01)\n",
    "        self.c_net_2.bias.data.fill_(0.0)\n",
    "        \n",
    "        self.c_net_3 = nn.Linear(self.f_net.output_dim, 3)#target\n",
    "        self.c_net_3.weight.data.normal_(0, 0.01)\n",
    "        self.c_net_3.bias.data.fill_(0.0)\n",
    "        \n",
    "        self.c_net_4 = nn.Linear(self.f_net.output_dim, 3) \n",
    "        self.c_net_4.weight.data.normal_(0, 0.01)\n",
    "        self.c_net_4.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.f_net(x)\n",
    "        out_1 = self.c_net_1(feature)\n",
    "        out_2 = self.c_net_2(feature)\n",
    "       \n",
    "        out_3 = self.c_net_3(feature)#target\n",
    "        out_4 = self.c_net_4(feature)\n",
    "\n",
    "        return out_1, out_2, out_3, out_4\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Net().cuda()\n",
    "model = Net()#.cuda()\n",
    "model.to(device)\n",
    "print(get_last_conv_name(model))\n",
    "#batch_size = 2\n",
    "log_var_a = torch.zeros((400,), requires_grad=True)\n",
    "log_var_b = torch.zeros((3,), requires_grad=True)\n",
    "#print(get_last_conv_name(model))\n",
    "a = torch.exp(-log_var_a) ** 2\n",
    "b = torch.exp(-log_var_b) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(loader):\n",
    "    idx = 0\n",
    "    train_labels_list = []\n",
    "    imagenet_labels_list = []\n",
    "    for step, batch in enumerate(loader, 1):\n",
    "        model.eval()\n",
    "        train_inputs = batch[\"X\"] \n",
    "        train_labels = batch[\"y\"] \n",
    "        #for train_inputs, train_labels in tqdm(loader):\n",
    "        train_labels_list.append(train_labels)\n",
    "        train_inputs, train_labels = train_inputs.to(device), train_labels.to(device)\n",
    "        imagenet_labels, var_1, _, var_2 = model(train_inputs)\n",
    "        #print(imagenet_labels)\n",
    "        imagenet_labels = imagenet_labels.detach().cpu().numpy()\n",
    "        imagenet_labels_list.append(imagenet_labels)\n",
    "       \n",
    "    all_train_labels = np.concatenate(train_labels_list, 0)\n",
    "    all_imagenet_labels = np.concatenate(imagenet_labels_list, 0)\n",
    "\n",
    "    return all_imagenet_labels, all_train_labels\n",
    "\n",
    "train_imagenet_labels, train_train_labels = get_feature(train_loader)\n",
    "val_imagenet_labels, val_train_labels = get_feature(valid_loader)\n",
    "relationship = relationship_learning(train_imagenet_labels, train_train_labels, val_imagenet_labels, val_train_labels)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93396c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.benchmark = True\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model,\n",
    "        device,\n",
    "        optimizer, \n",
    "        scheduler,\n",
    "        criterion1,\n",
    "        criterion2,\n",
    "        trade_off,\n",
    "        log_var_a,\n",
    "        log_var_b,\n",
    "        a,\n",
    "        b\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion1 = criterion1\n",
    "        self.criterion2 = criterion2\n",
    "        self.trade_off = trade_off\n",
    "        self.log_var_a = log_var_a\n",
    "        self.log_var_b = log_var_b\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        self.best_valid_score = np.inf\n",
    "        self.n_patience = 0\n",
    "        self.lastmodel = None\n",
    "        \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n",
    "        writer = SummaryWriter()\n",
    "        start_time = time.time()\n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_ce_loss, train_imagenet_loss, train_loss, train_time = self.train_epoch(train_loader)\n",
    "            \n",
    "            valid_ce_loss, valid_imagenet_loss, valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            \n",
    "            \n",
    "            writer.add_scalar(\"Train_ce_loss\", train_ce_loss, n_epoch)\n",
    "            writer.add_scalar(\"Train_imagenet_loss\", train_imagenet_loss, n_epoch)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            writer.add_scalar(\"Train_loss\", train_loss, n_epoch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            writer.add_scalar(\"Valid_ce_loss\", valid_ce_loss, n_epoch)\n",
    "            writer.add_scalar(\"Valid_imagenet_loss\", valid_imagenet_loss, n_epoch)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s \",\n",
    "                n_epoch, valid_loss, valid_auc, valid_time\n",
    "            )\n",
    "            writer.add_scalar(\"Valid_auc\", valid_auc, n_epoch)\n",
    "            \n",
    "            if self.best_valid_score > valid_loss:\n",
    "                self.save_model(n_epoch, save_path)\n",
    "                self.info_message(\n",
    "                    \"Auc improved from {:.4f} to {:.4f}. Saved model to '{}'\",\n",
    "                    self.best_valid_score, valid_loss, self.lastmodel\n",
    "                )\n",
    "                self.best_valid_score = valid_loss\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            writer.add_scalar(\"Valid_loss\", valid_loss, n_epoch)\n",
    "        \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n",
    "                break\n",
    "        time_took = time.time() - start_time\n",
    "        print(f\"train completed, time took: {hms_string(time_took)}.\")\n",
    "        writer.close()\n",
    "                \n",
    "                \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_ce_loss = 0\n",
    "        sum_imagenet_loss = 0\n",
    "        sum_loss = 0\n",
    "    \n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            train_inputs = batch[\"X\"].to(self.device)\n",
    "            train_labels = batch[\"y\"].to(self.device)\n",
    "            ind = train_labels.argmax(dim=1)\n",
    "            ind = torch.Tensor.cpu(ind)\n",
    "            #print(ind)\n",
    "            #print(relationship[ind].shape)\n",
    "            imagenet_targets = torch.from_numpy(relationship[ind]).to(self.device).float()\n",
    "            imagenet_outputs, var_1, train_outputs, var_2 = self.model(train_inputs)\n",
    "            #print(var)\n",
    "            #outputs = self.model(X).squeeze(1)\n",
    "            #loss = self.criterion(outputs, targets)\n",
    "            #sum_loss += loss.item()\n",
    "            #train_outputs = train_outputs.squeeze(1)\n",
    "            \n",
    "            # assume that each logit value is drawn from Gaussian distribution, therefore the whole logit vector is drawn from multi-dimensional Gaussian distribution\n",
    "            epsilon_1 = torch.randn(var_1.size()).to(self.device)\n",
    "            logit_1 = imagenet_outputs + torch.mul(var_1, epsilon_1)\n",
    "            #print(logit)\n",
    "            imagenet_outputs = logit_1#F.softmax(logit, dim=1)\n",
    "            \n",
    "            epsilon_2 = torch.randn(var_2.size()).to(self.device)\n",
    "            logit_2 = train_outputs + torch.mul(var_2, epsilon_2)\n",
    "            #print(logit)\n",
    "            train_outputs = logit_2#F.softmax(logit, dim=1)\n",
    "            \n",
    "            #print(self.log_var_a.shape)\n",
    "            #print(self.log_var_a)\n",
    "            self.log_var_a = torch.tensor(var_1, requires_grad=True)\n",
    "            self.log_var_b = torch.tensor(var_2, requires_grad=True)\n",
    "            #print(self.log_var_a.shape)\n",
    "            #print(self.log_var_a)\n",
    "            \n",
    "            self.a = torch.exp(-self.log_var_a) ** 2\n",
    "            self.b = torch.exp(-self.log_var_b) ** 2\n",
    "\n",
    "            #print(F.softmax(logit, dim=1))\n",
    "            #print(train_outputs)\n",
    "            #ce_loss = self.criterion1(train_outputs, train_labels)\n",
    "            #imagenet_loss = - imagenet_targets * self.criterion2(imagenet_outputs)\n",
    "            #imagenet_loss = torch.mean(torch.sum(imagenet_loss, dim=-1))\n",
    "            #loss = ce_loss + self.trade_off * imagenet_loss\n",
    "            imagenet_loss = - self.a * imagenet_targets * self.criterion2(imagenet_outputs)\n",
    "            imagenet_loss = torch.mean(torch.sum(imagenet_loss, dim=-1))\n",
    "            \n",
    "            ce_loss = - self.b * train_labels * self.criterion2(train_outputs)\n",
    "            ce_loss = torch.mean(torch.sum(ce_loss, dim=-1))\n",
    "            #ce_loss = self.criterion1(train_outputs, train_labels)\n",
    "            \n",
    "            #print(imagenet_targets.shape)\n",
    "            #print(imagenet_outputs.shape)\n",
    "            #print(imagenet_loss)\n",
    "            #print(ce_loss)\n",
    "            #print(ce_loss.item())\n",
    "            #print(imagenet_loss)\n",
    "            #print(imagenet_loss.item())\n",
    "            #print(self.trade_off)\n",
    "            loss = ce_loss + imagenet_loss + torch.mean(self.log_var_a) + torch.mean(self.log_var_b)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            sum_ce_loss += ce_loss.item()\n",
    "            sum_imagenet_loss += imagenet_loss.item()\n",
    "            sum_loss += loss\n",
    "            \n",
    "            message = \"Train Step {}/{}, train_ce_loss: {:.4f}\"\n",
    "            self.info_message(message, step, len(train_loader), sum_ce_loss/step, end=\"\\r\")\n",
    "            \n",
    "            message = \"Train Step {}/{}, train_imagenet_loss: {:.4f}\"\n",
    "            self.info_message(message, step, len(train_loader), sum_imagenet_loss/step, end=\"\\r\")\n",
    "            \n",
    "            message = \"Train Step {}/{}, train_loss: {:.4f}\"\n",
    "            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n",
    "        self.scheduler.step()\n",
    "        return sum_ce_loss/len(train_loader), sum_imagenet_loss/len(train_loader), sum_loss/len(train_loader), int(time.time()-t)\n",
    "\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_ce_loss = 0\n",
    "        sum_imagenet_loss = 0\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "        num_correct = 0.0\n",
    "        metric_count = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, batch in enumerate(valid_loader, 1):\n",
    "                val_inputs = batch[\"X\"].to(self.device)\n",
    "                #print(X.shape)\n",
    "                val_labels = batch[\"y\"].to(self.device)\n",
    "                #print(targets.shape)\n",
    "                #outputs = self.model(X).squeeze(1)\n",
    "                ind = val_labels.argmax(dim=1)\n",
    "                ind = torch.Tensor.cpu(ind)\n",
    "                #print(ind)\n",
    "                #print(relationship[ind].shape)\n",
    "                val_imagenet_targets = torch.from_numpy(relationship[ind]).to(self.device).float()\n",
    "                val_imagenet_outputs, var1_, val_outputs, var_2 = self.model(val_inputs)\n",
    "                #val_outputs = val_outputs.squeeze(1)\n",
    "                #loss = self.criterion(outputs, targets)\n",
    "                #sum_loss += loss.item()\n",
    "\n",
    "                #ce_loss = self.criterion1(val_outputs, val_labels)\n",
    "                #sum_ce_loss += ce_loss.item()\n",
    "            \n",
    "                #imagenet_loss = - val_imagenet_targets * self.criterion2(val_imagenet_outputs)\n",
    "                #imagenet_loss = torch.mean(torch.sum(imagenet_loss, dim=-1))\n",
    "                #sum_imagenet_loss += imagenet_loss.item()\n",
    "            \n",
    "                #loss = ce_loss + self.trade_off * imagenet_loss\n",
    "                #sum_loss += loss\n",
    "                imagenet_loss = - self.a * val_imagenet_targets * self.criterion2(val_imagenet_outputs)\n",
    "                imagenet_loss = torch.mean(torch.sum(imagenet_loss, dim=-1))\n",
    "                ce_loss = - self.b * val_labels * self.criterion2(val_outputs)\n",
    "                ce_loss = torch.mean(torch.sum(ce_loss, dim=-1))\n",
    "                # ce_loss = self.criterion1(train_outputs, train_labels)\n",
    "                \n",
    "                # print(imagenet_targets.shape)\n",
    "                # print(imagenet_outputs.shape)\n",
    "                # print(imagenet_loss)\n",
    "                # print(ce_loss)\n",
    "                # print(ce_loss.item())\n",
    "                # print(imagenet_loss)\n",
    "                # print(imagenet_loss.item())\n",
    "                # print(self.trade_off)\n",
    "                loss = ce_loss + imagenet_loss + torch.mean(self.log_var_a) + torch.mean(self.log_var_b)\n",
    "\n",
    "                sum_ce_loss += ce_loss.item()\n",
    "                sum_imagenet_loss += imagenet_loss.item()\n",
    "                sum_loss += loss.item()\n",
    "                \n",
    "                value = torch.eq(torch.sigmoid(val_outputs).argmax(dim=1), val_labels.argmax(dim=1))\n",
    "                metric_count += len(value)\n",
    "                num_correct += value.sum().item()\n",
    "        \n",
    "                y_all.extend(batch[\"y\"].argmax(dim=1).tolist())\n",
    "                outputs_all.extend(torch.sigmoid(val_outputs).argmax(dim=1).tolist())\n",
    "            \n",
    "                message = \"Valid Step {}/{}, valid_ce_loss: {:.4f}\"\n",
    "                self.info_message(message, step, len(valid_loader), sum_ce_loss/step, end=\"\\r\")\n",
    "                message = \"Valid Step {}/{}, valid_imagenet_loss: {:.4f}\"\n",
    "                self.info_message(message, step, len(valid_loader), sum_imagenet_loss/step, end=\"\\r\")\n",
    "                message = \"Valid Step {}/{}, valid_loss: {:.4f}\"\n",
    "                self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n",
    "        \n",
    "        \n",
    "            auc = num_correct / metric_count\n",
    "            #metric_values.append(metric)\n",
    "            #auc = roc_auc_score(y_all, torch.Tensor.cpu(outputs))\n",
    "            #outputs_all = [1 if y > 0.5 else 0 for y in outputs_all]\n",
    "            #auc_ = roc_auc_score(y_all, outputs_all)\n",
    "            print(precision_recall_fscore_support(y_all, outputs_all))\n",
    "        \n",
    "            return sum_ce_loss/len(valid_loader), sum_imagenet_loss/len(valid_loader), sum_loss/len(valid_loader), auc, int(time.time()-t) \n",
    "        \n",
    "    \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "        self.lastmodel = f\"{save_path}-cofinetuneresnet_min_loss_model_classification3d_array_newloss.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            self.lastmodel,\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6925431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_all_type(train_loader, valid_loader, mri_type=\"all\"):\n",
    "    model = Net()#.cuda()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam([p for p in model.parameters()] + [log_var_a] + [log_var_b], lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    criterion1 = torch.nn.CrossEntropyLoss()#torch_functional.binary_cross_entropy_with_logits\n",
    "    criterion2 = torch.nn.LogSoftmax(dim=-1)\n",
    "    trade_off = 2.3\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        criterion1, \n",
    "        criterion2,\n",
    "        trade_off,\n",
    "        log_var_a,\n",
    "        log_var_b,\n",
    "        a,\n",
    "        b\n",
    "    )\n",
    "    \n",
    "    history = trainer.fit(\n",
    "        20, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        f\"{mri_type}\",\n",
    "        10,\n",
    "    )\n",
    "    \n",
    "    return trainer.lastmodel\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modelfile = train_all_type(train_loader, valid_loader, \"all\")\n",
    "    print(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8611c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_image_3d(scan_id=\"Pcnls_84\")\n",
    "\n",
    "a = np.array(a)\n",
    "a = torch.tensor(a, dtype=torch.float32)\n",
    "print(a.shape)\n",
    "print(a[0].shape)\n",
    "show_plt(a[0], \"Flair\")\n",
    "b = a.unsqueeze(0)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f922f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_name_(model):\n",
    "    layer_name = None\n",
    "    mm = None\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, nn.Conv3d):\n",
    "            layer_name = name\n",
    "            mm = m\n",
    "            #print(m)\n",
    "            #print(layer_name)\n",
    "    return layer_name\n",
    "\n",
    "model = Net()\n",
    "print(get_last_conv_name_(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f66388",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelfile = \"all-cofinetuneresnet_min_loss_model_classification3d_array_newloss.pth\"\n",
    "checkpoint_new = torch.load(modelfile)\n",
    "class Net_New(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_New, self).__init__()\n",
    "        net = Net()\n",
    "        net.load_state_dict(checkpoint_new[\"model_state_dict\"]) \n",
    "        self.net_1 = net.f_net \n",
    "        self.net_3 = net.c_net_3\n",
    "    def forward(self, x):\n",
    "        x = self.net_1(x)\n",
    "        out_3 = self.net_3(x)#target\n",
    "        return out_3\n",
    "\n",
    "print(get_last_conv_name_(Net_New()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medCAM(channelimg):\n",
    "    for i, j in enumerate((\"Flair\", #\"T1\", \"T13D\", \n",
    "                           \"T2\")):\n",
    "        #print(j)\n",
    "        channelimg = np.array(channelimg)\n",
    "        tensor = torch.tensor(channelimg, dtype=torch.float32).unsqueeze(0)\n",
    "   \n",
    "        tensor = tensor.to(device)#cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "        #model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=2, out_channels=2)#.to(device)\n",
    "        #model = Model()\n",
    "        \n",
    "        Model = Net_New()#.cuda()\n",
    "        Model.to(device)\n",
    "        #checkpoint = torch.load(modelfile)\n",
    "        #Model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "        layer_name = get_last_conv_name_(Model)\n",
    "        #print(layer_name)\n",
    "        model = medcam.inject(Model, output_dir=\"attention_maps\", backend=\"gcam\", layer=layer_name, label=2, replace=True, return_score=True)\n",
    "        model.eval()\n",
    "        output = model(tensor)\n",
    "        \n",
    "        xyz = medcam.save(output[0].squeeze(0).squeeze(0), f\"attention_maps\\\\{j}\\\\{modelfile}\", heatmap=True, raw_input=None)\n",
    "        \n",
    "        x = torch.Tensor.cpu(output[0].squeeze(0).squeeze(0))\n",
    "        y = channelimg[i]\n",
    "        z = x + y\n",
    "    \n",
    "        xyz_ = medcam.save(z, f\"attention_maps_\\\\{j}\\\\{modelfile}\", heatmap=True, raw_input=None)\n",
    "        \n",
    "        #show_plt(z)\n",
    "        show_plt_(z)\n",
    "        #show_plt_(torch.Tensor.cpu(output[0].squeeze(0).squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "medCAM(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed41825",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_files = (\"Flair_res111.nii.gz\", \"T1_res111.nii.gz\", \"T13D_res111.nii.gz\", \"T2_res111.nii.gz\")\n",
    "data_directory=\"D:\\\\down\"\n",
    "df_test = pd.read_csv(f\"{data_directory}\\\\test.csv\")\n",
    "display(df_test)\n",
    "scan_ids_test = list(df_test[\"Patient\"])\n",
    "for scan_id_test in scan_ids_test:\n",
    "    get_foreground_from_set_of_files(scan_id_test, set_of_files, background_value=0, tolerance=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_test = pd.get_dummies(df_test[\"OS 1 year\"]) # Classification\n",
    "cats = [0,1,2]\n",
    "dummies_test = dummies_test.T.reindex(cats).T.fillna(0)\n",
    "products_test = dummies_test.columns\n",
    "y_test = dummies_test.values\n",
    "print(products_test)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4713209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred, pos_label={1})\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #print(roc_auc)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve (Area = %0.2f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\".\\\\roc.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fda873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(products_test):\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            #AsChannelFirst(),\n",
    "            Resize(spatial_size=(128, 128, 128)),\n",
    "            #RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "            #RandFlip(spatial_axis=0, prob=0.5),\n",
    "            ScaleIntensity(),\n",
    "            EnsureType(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    test_data_retriever = Dataset(\n",
    "        paths=df_test[\"Patient\"].values,\n",
    "        targets=y_test,\n",
    "        transforms=test_transforms\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(#torch_data.DataLoader(\n",
    "        test_data_retriever,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "        #collate_fn=pad_list_data_collate\n",
    "    )\n",
    "\n",
    "    Model = Net_New()#.cuda()\n",
    "    Model.to(device)\n",
    "    \n",
    "    \n",
    "    Model.eval()\n",
    "    \n",
    "    \n",
    "    y_label = []\n",
    "    y_pred = []\n",
    "    num_correct = 0.0\n",
    "    metric_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for e, batch in enumerate(test_loader,1):\n",
    "            print(\"{}/{}\".format(e, len(test_loader)), end=\"\\r\")\n",
    "            test_inputs = batch[\"X\"].to(device)\n",
    "            test_labels = batch[\"y\"].to(device)\n",
    "            ind = test_labels.argmax(dim=1)\n",
    "            ind = torch.Tensor.cpu(ind)\n",
    "            test_outputs = Model(test_inputs)\n",
    "           \n",
    "            value = torch.eq(torch.sigmoid(test_outputs).argmax(dim=1), test_labels.argmax(dim=1))\n",
    "            metric_count += len(value)\n",
    "            num_correct += value.sum().item()\n",
    "            \n",
    "            y_label.append(batch[\"y\"].argmax(dim=1).tolist())\n",
    "            y_pred.append(torch.sigmoid(test_outputs).argmax(dim=1).tolist())\n",
    "        \n",
    "        auc = num_correct / metric_count\n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(y_label, y_pred, average='macro')\n",
    "        plot_roc(y_label, y_pred) \n",
    "        cm = confusion_matrix(y_label, y_pred)\n",
    "        #np.set_printoptions(precision=2)\n",
    "        cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cm_normalized, products_test, title=\"Normalized Confusion Matrix\")\n",
    "        #plot_confusion_matrix(cm, products_test, title='Normalized confusion matrix')\n",
    "        plt.savefig(\".\\\\cm.jpg\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"auc =\", auc)\n",
    "        print(\"precision =\", precision)\n",
    "        print(\"recall =\", recall)\n",
    "        print(\"fscore =\", fscore)\n",
    "        return auc, precision, recall, fscore, support\n",
    "        \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e277fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(products_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030840e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
